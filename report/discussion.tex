\section{Discussion}
\label{sec:discussion}

Our experimental results demonstrate the effectiveness of feature-based sequence modeling for drug name recognition in biomedical text. The significant performance gap between the CRF and Na√Øve Bayes models highlights the importance of modeling label dependencies in sequence labeling tasks. By considering the entire sequence of labels, the CRF can enforce consistency constraints (e.g., an I-tag must follow a B-tag of the same type) and capture transition patterns that are common in the data.

The feature ablation study provides valuable insights into the relative importance of different feature types. The substantial impact of lexicon features underscores the value of domain knowledge in specialized NER tasks. By incorporating lists of known drug names and categories, we can help the model recognize entities that might be rare or absent in the training data. This is particularly important in the biomedical domain, where new drug names are constantly being introduced, and coverage of all possible entities in a training set is impractical.

Contextual features also proved crucial, confirming that the surrounding words provide important clues for entity recognition. Many drug names appear in specific contexts (e.g., followed by dosage information or preceded by administration routes), and capturing these patterns helps the model make more accurate predictions. The window-based approach we implemented (considering the previous and next tokens) provides a simple but effective way to incorporate local context. More sophisticated contextual modeling, such as longer context windows or attention mechanisms, could potentially yield further improvements.

While our system achieved competitive results, there are several limitations worth noting. First, our approach relies heavily on manually engineered features, which requires domain expertise and may not generalize well to other entity types or domains. Second, the lexicon-based features, while effective, are limited by the coverage and quality of the available lexicons. Expanding these resources or developing methods to automatically extract potential drug names from unlabeled text could enhance performance. Third, our models do not leverage the rich semantic information available in biomedical text, such as relationships between entities or domain-specific terminology.

Comparing our results to those reported in the SemEval-2013 DDI challenge~\cite{semeval2013}, we find that our CRF-based system performs competitively with many participating systems. The top-performing systems in that challenge typically employed ensemble methods, more extensive feature engineering, or domain-specific post-processing rules. Our relatively simpler approach, focusing on a single CRF model with a carefully selected feature set, achieves a good balance between performance and complexity.

The error analysis revealed interesting patterns in misclassifications, particularly the confusion between "drug" and "group" categories. This confusion often stems from ambiguous terms that can refer to both a specific drug and a class of drugs, depending on the context. For example, "insulin" can refer to the specific hormone (drug) or to the class of insulin medications (group). Resolving such ambiguities would require deeper semantic understanding or more sophisticated contextual modeling than our current approach provides.

The challenges with the "drug\_n" category highlight the difficulty of recognizing entities with heterogeneous naming patterns and limited training examples. This category includes experimental compounds, toxins, and other substances not approved for human use, each with potentially unique naming conventions. Improving performance on this category might require specialized features or additional external resources focused on these types of substances.
